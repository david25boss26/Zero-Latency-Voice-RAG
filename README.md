# Zero-Latency-Voice-RAG
Real-Time Voice-Based Retrieval-Augmented Generation for Technical Support

#ğŸ“Œ Project Overview
This project implements a Zero-Latency Voice-Driven Retrieval-Augmented Generation (RAG) system designed to simulate a real-world technical support assistant for enterprise hardware manuals (e.g., Dell PowerEdge servers).

The system supports:

ğŸ™ï¸ Real-time voice input (ASR simulation)

âš¡ Speculative retrieval while the user is still speaking

ğŸ“š Hybrid document search (FAISS + BM25)

ğŸ§  Cross-encoder reranking

ğŸ—£ï¸ Natural spoken responses using TTS

#ğŸ§  Methodology
1ï¸âƒ£ Problem Framing

Traditional RAG systems suffer from:

High latency

Blocking pipelines

Slow first token response

Poor conversational handling

This project solves that by introducing:

âœ… Parallel execution
âœ… Speculative retrieval
âœ… Streaming input handling
âœ… Voice-first interaction design



â±ï¸ Optimized Time-To-First-Byte (TTFB)

The goal is to minimize perceived latency while maintaining high answer accuracy.

#2ï¸âƒ£ System Design Philosophy

The system is built around three principles:

âš¡ 1. Parallelism Over Sequential Processing

Instead of:
User speaks â†’ ASR â†’ Retrieval â†’ LLM â†’ TTS

We do:
User speaks
   â†“
ASR streaming â”€â”€â”€â”€â”€â”€â”
                     â”œâ”€â”€ Retrieval starts early
                     â””â”€â”€ TTS prepares response

#ğŸ§  2. Hybrid Retrieval for Accuracy
Single retrieval methods fail in edge cases.
So we use:

FAISS â†’ semantic similarity

BM25 â†’ keyword matching

Cross-Encoder â†’ deep reranking

This ensures:
High recall
High precision
Robust performance on technical text

#ğŸ—£ï¸ 3. Voice-First Output Design
Instead of dumping raw text:

Sentences are shortened
Technical terms are normalized
Output is optimized for speech clarity
Example:
PCIe â†’ P C I express
iDRAC â†’ eye-drack

#âš™ï¸ Technical Architecture

User Voice
   â†“
ASR (Streaming)
   â†“
Speculative RAG Trigger
   â†“
Hybrid Search (FAISS + BM25)
   â†“
Cross-Encoder Reranking
   â†“
LLM Answer Generation
   â†“
Speech Optimization
   â†“
Text-to-Speech Output


#ğŸ§© Component Breakdown
#ğŸ“ ingest/
File Purpose: 
parse_pdf.py -> Extracts text from manuals 
chunker.py -> Splits text into semantic chunks
build_index.py -> Builds FAISS + BM25 index

#ğŸ“ rag/
File Purpose: 
vector_search.py -> FAISS-based retrieval 
bm25_search.py -> Keyword search
reranker.py -> Cross-encoder ranking
hybrid.py -> Combines all retrieval logic

#ğŸ“ voice/
File Purpose:
asr_stream.py -> Simulates streaming ASR
tts_stream.py -> Async TTS using pyttsx3

#ğŸ“ core/
File Purpose: 
orchestrator.py -> Controls entire pipeline

#ğŸ“„ demo.py
Entry point for running the system.

#ğŸ§  Core Logic Explained
ğŸ”¹ Speculative RAG
As soon as 4â€“5 words are detected:
RAG pipeline starts
Retrieval happens before user finishes speaking
Reduces perceived latency

ğŸ”¹ Query Rewriting
Handles follow-ups like:
â€œWhat about the second one?â€
â€œAnd that error?â€

Uses:
Previous user query
Last retrieved documents

ğŸ”¹ Reranking
Uses:
cross-encoder/ms-marco-MiniLM-L-6-v2
To score (query, passage) relevance accurately.

ğŸ”¹ LLM Prompt Control
LLM is constrained to:
Use only retrieved context
Avoid hallucination
Answer in 2â€“4 short sentences
Be voice-friendly



#ğŸ§ª Setup Instructions
#âœ… Step 1: Clone Repository
git clone https://github.com/david25boss26/Zero-Latency-Voice-RAG.git
cd Zero-Latency-Voice-RAG


#âœ… Step 2: Create Virtual Environment
python -m venv venv
venv\Scripts\activate


#âœ… Step 3: Install Dependencies
pip install -r requirements.txt


#âœ… Step 4: Build Index
cd ingest
python chunker.py
python build_index.py


#âœ… Step 5: Run System
python demo.py


#ğŸ¤ Example Interaction
User: my server shows error 46 and second light blinking

[ASR partial] my server shows
âš¡ starting speculative RAG...

AI:
Error code 46 usually indicates a hardware communication issue.
The blinking second LED suggests a component initialization failure.
I recommend checking the system logs or reseating the affected module.


ğŸš€ Performance Highlights
MetricResultTTFB~600â€“800 msRetrievalParallelResponseStreamingAccuracyHigh (reranked)Voice LatencyLow

ğŸ‘¨â€ğŸ’» Author
David Sharma
AI Systems | Voice AI | Retrieval Engineering
GitHub:
ğŸ‘‰ https://github.com/david25boss26

âœ… Final Notes
This project demonstrates:

Real-world RAG design
Low-latency AI systems
Production-grade architecture
Voice-first AI interaction
Advanced async orchestration



